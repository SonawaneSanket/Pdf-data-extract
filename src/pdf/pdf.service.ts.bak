// src/pdf/pdf.service.ts
import { Injectable, HttpException, HttpStatus } from '@nestjs/common';
import { join } from 'path';
import * as fs from 'fs';
import * as crypto from 'crypto';
import * as Poppler from 'pdf-poppler';
import * as tesseract from 'node-tesseract-ocr';
import fetch from 'node-fetch';
import { ImageAnnotatorClient } from '@google-cloud/vision';
import * as sharp from 'sharp';
import { exec } from 'child_process';
import * as util from 'util';
import * as path from 'path';
import * as pdfjsLib from 'pdfjs-dist';
import { PDFDocument } from 'pdf-lib';
import * as os from 'os';

export interface PageSummary {
  imageUrl: string;
  title: string;
  description: string;
  embeddedImages: string[];
  logos: string[];
  photos: string[];
  faces: string[];
  scenes: string[];
}

const sleep = (ms: number) => new Promise((resolve) => setTimeout(resolve, ms));

@Injectable()
export class PdfService {
  private readonly mistralUrl = 'https://api.mistral.ai/v1/chat/completions';
  private readonly mistralKey = process.env.MISTRAL_API_KEY;
  private readonly visionClient = new ImageAnnotatorClient();
  private readonly processedImageHashes = new Set<string>(); // Track processed image hashes

  public async getFileHash(filePath: string): Promise<string> {
    const buffer = await fs.promises.readFile(filePath);
    return crypto.createHash('sha256').update(buffer).digest('hex');
  }

  private async getImageHash(imagePath: string): Promise<string> {
    const buffer = await fs.promises.readFile(imagePath);
    return crypto.createHash('sha256').update(buffer).digest('hex');
  }
  private async isValidImage(imagePath: string): Promise<boolean> {
    console.log(`Validating image at path: ${imagePath}`);
    try {
      // Get image metadata
      const metadata = await sharp(imagePath).metadata();
      const { width = 0, height = 0 } = metadata;

      // Skip very small images
      if (width < 50 || height < 50) {
        console.log(`Image too small: ${width}x${height}`);
        return false;
      }

      // Skip images with extreme aspect ratios
      const aspectRatio = width / height;
      if (aspectRatio > 5 || aspectRatio < 0.2) {
        console.log(`Extreme aspect ratio: ${aspectRatio}`);
        return false;
      }

      // Check for image content quality
      const { data } = await sharp(imagePath)
        .raw()
        .toBuffer({ resolveWithObject: true });
      console.log(`Raw data extracted from image. Data length: ${data.length}`);

      // Calculate average pixel value
      const avg = data.reduce((sum, val) => sum + val, 0) / data.length;
      console.log(`Calculated average pixel value: ${avg}`);

      // Calculate standard deviation to detect contrast
      let sumSquareDiff = 0;
      for (const val of data) {
        sumSquareDiff += Math.pow(val - avg, 2);
      }
      const stdDev = Math.sqrt(sumSquareDiff / data.length);
      console.log(`Standard deviation (contrast): ${stdDev}`);

      // Check for valid range of average pixel value and sufficient contrast
      if (avg > 10 && avg < 245 && stdDev > 15) {
        console.log(`Image is valid with good contrast and pixel values.`);
        return true;
      } else {
        console.log(`Image is invalid. Avg: ${avg}, StdDev: ${stdDev}`);
        return false;
      }
    } catch (err) {
      console.error(
        `Error validating image ${imagePath}:`,
        (err as Error).message,
      );
      return false;
    }
  }

  private async checkToolAvailability(tool: string): Promise<boolean> {
    console.log(`Checking availability of ${tool}...`);
    try {
      const execAsync = util.promisify(exec);
      await execAsync(`${tool} -h`, { timeout: 2000 });
      console.log(`${tool} is available`);
      return true;
    } catch (e) {
      console.log(`${tool} is not available: ${(e as Error).message}`);
      return false;
    }
  }

  private async extractWithNativeTools(
    pdfPath: string, 
    outputDir: string
  ): Promise<boolean> {
    console.log(`Attempting to extract images using native tools`);
    const execAsync = util.promisify(exec);
    const imgPrefix = join(outputDir, 'embedded');
    let success = false;

    // 1) Extract bitmaps via pdfimages if available
    if (await this.checkToolAvailability('pdfimages')) {
      try {
        console.log(`Running pdfimages to extract bitmaps...`);
        await execAsync(`pdfimages -all "${pdfPath}" "${imgPrefix}"`);
        success = true;
      } catch (err) {
        console.error(`Error running pdfimages: ${(err as Error).message}`);
      }
    }

    // 2) Extract vectors via pdftocairo if available
    if (await this.checkToolAvailability('pdftocairo')) {
      try {
        console.log(`Running pdftocairo to extract SVGs...`);
        await execAsync(`pdftocairo -svg "${pdfPath}" "${imgPrefix}"`);
        success = true;
      } catch (err) {
        console.error(`Error running pdftocairo: ${(err as Error).message}`);
      }
    }

    return success;
  }

  private async extractWithPdfJs(
    pdfPath: string,
    outputDir: string
  ): Promise<boolean> {
    console.log('Extracting images using PDF.js library');
    try {
      // Set up PDF.js worker
      const pdfjsPath = require.resolve('pdfjs-dist/build/pdf.worker.js');
      if (pdfjsPath) {
        pdfjsLib.GlobalWorkerOptions.workerSrc = pdfjsPath;
      }

      // Load the PDF document
      const loadingTask = pdfjsLib.getDocument(pdfPath);
      const pdf = await loadingTask.promise;
      console.log(`PDF loaded with ${pdf.numPages} pages using PDF.js`);

      let imagesExtracted = false;

      // Process each page
      for (let i = 1; i <= pdf.numPages; i++) {
        try {
          console.log(`Processing page ${i} of ${pdf.numPages}`);
          const page = await pdf.getPage(i);

          // Get the operator list which contains drawing operations
          const opList = await page.getOperatorList();

          // This is a simplified approach that works with the PDF.js API
          // We'll extract image data from the page's operator list
          for (let j = 0; j < opList.fnArray.length; j++) {
            const op = opList.fnArray[j];
            const args = opList.argsArray[j];

            // Look for image drawing operations
            if (op === pdfjsLib.OPS.paintImageXObject) {
              const imgId = args[0];

              try {
                // @ts-ignore - Accessing internal properties
                const imgObj = page.objs?.get(imgId);

                if (!imgObj || !imgObj.data) continue;

                const imageData = imgObj.data;
                
                // Save the image data
                const imageFileName = `js_extracted_${i}_${imgId.replace(/[^a-z0-9]/gi, '_')}.png`;
                const imagePath = join(outputDir, imageFileName);

                try {
                  // Save image data as PNG
                  await fs.promises.writeFile(imagePath, Buffer.from(imageData));
                  imagesExtracted = true;
                } catch (err) {
                  console.error(`Error saving PDF.js image: ${(err as Error).message}`);
                }
              } catch (err) {
                console.error(`Error processing image ${imgId}: ${(err as Error).message}`);
              }
            }
          }
        } catch (err) {
          console.error(`Error processing page ${i}: ${(err as Error).message}`);
        }
      }
      return imagesExtracted;
    } catch (err) {
      console.error(`Error using PDF.js extraction: ${(err as Error).message}`);
      return false;
    }
  }

  private async extractEmbeddedImages(
    pdfPath: string,
    outputDir: string,
    fileHash: string,
  ): Promise<string[]> {
    console.log(`Extracting embedded images directly from PDF structure: ${pdfPath}`);
    const validImagePaths: string[] = [];

    try {
      // First try using pdf-lib for direct extraction
      const pdfBytes = await fs.promises.readFile(pdfPath);
      const pdfDoc = await PDFDocument.load(pdfBytes);
      console.log(`PDF loaded with ${pdfDoc.getPageCount()} pages using pdf-lib`);

      // Track processed image hashes to avoid duplicates
      const processedImageHashes = new Set<string>();
      
      // Check platform and try appropriate extraction methods
      const isWindows = process.platform === 'win32';
      console.log(`Running on ${isWindows ? 'Windows' : 'non-Windows'} platform`);
      
      let extractionSuccess = false;
      
      // Only try native tools if not on Windows, or check if tools are installed on Windows
      if (!isWindows || (await this.checkToolAvailability('pdfimages'))) {
        extractionSuccess = await this.extractWithNativeTools(pdfPath, outputDir);
      }
      
      // If native tools failed or not available, use PDF.js as fallback
      if (!extractionSuccess) {
        console.log('Native tools failed or not available, using PDF.js extraction as fallback');
        await this.extractWithPdfJs(pdfPath, outputDir);
      }

      // 3) Collect all extracted image files
      const files = fs
        .readdirSync(outputDir)
        .filter((f) =>
          // include PNG/JPG/JP2/TIFF bitmaps and SVG vectors
          /\.(png|jpe?g|jp2?|tiff?|svg)$/i.test(f),
        )
        .sort();

      console.log(`Found ${files.length} embedded assets:`, files);

      // Process each file
      for (const file of files) {
        const fullPath = join(outputDir, file);

        try {
          // Generate a hash to identify duplicate images
          const imageHash = await this.getImageHash(fullPath);

          // Skip if we've already processed this image
          if (processedImageHashes.has(imageHash)) {
            console.log(`Skipping duplicate image with hash ${imageHash.substring(0, 8)}...`);
            continue;
          }

          processedImageHashes.add(imageHash);

          // For bitmaps, skip small ones
          if (/\.(png|jpe?g|jp2?|tiff?)$/i.test(file)) {
            try {
              const { width = 0, height = 0 } = await sharp(fullPath).metadata();
              if (width < 50 || height < 50) {
                console.log(`Skipping small bitmap: ${file} (${width}×${height})`);
                continue;
              }
            } catch (err) {
              console.log(`Couldn't read metadata for ${file}: ${(err as Error).message}`);
              continue;
            }
          }

          // SVGs: include all
          if (/\.svg$/i.test(file)) {
            console.log(`Including vector graphic: ${file}`);
          }

          // Validate the image
          if (await this.isValidImage(fullPath)) {
            console.log(`Valid embedded image: ${file}`);
            validImagePaths.push(`/files/${fileHash}/${file}`);
          } else {
            console.log(`Image failed validation: ${file}`);
          }
        } catch (err) {
          console.error(`Error processing file ${file}: ${(err as Error).message}`);
        }
      }

      // Process all files in the output directory to validate and deduplicate images
      // This happens regardless of extraction method used
    } catch (err) {
      console.error(`Error extracting embedded images: ${(err as Error).message}`);
    }

    console.log(`Extracted ${validImagePaths.length} valid embedded images.`);

    console.log(`Extracted ${validImagePaths.length} valid embedded images/vectors.`);
    return validImagePaths;
  }

  private async isDuplicateImage(imagePath: string): Promise<boolean> {
    const imageHash = await this.getImageHash(imagePath);
    if (this.processedImageHashes.has(imageHash)) {
      console.log(`Duplicate image detected: ${imagePath}`);
      return true;
    }
    this.processedImageHashes.add(imageHash);
    return false;
  }

  private async callMistral(text: string): Promise<{ title: string; description: string }> {
    try {
      if (!this.mistralKey) {
        return { 
          title: "[API key missing]", 
          description: "Please configure your Mistral API key to get AI summaries." 
        };
      }

      const response = await fetch(this.mistralUrl, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.mistralKey}`
        },
        body: JSON.stringify({
          model: 'mistral-large-latest',
          messages: [
            {
              role: 'system',
              content: 'Extract a concise title and description from the following text. Respond with a JSON object with "title" and "description" fields. Keep the title under 10 words and the description under 50 words.'
            },
            { role: 'user', content: text.substring(0, 1000) }
          ],
          response_format: { type: 'json_object' }
        })
      });

      if (!response.ok) {
        console.error(`Mistral API error: ${response.status} ${response.statusText}`);
        return { title: "[Processing Error]", description: "Failed to process text with AI." };
      }

      const data = await response.json();
      // Fix type safety issue
      const jsonData = data as any;
      const content = jsonData.choices?.[0]?.message?.content || '{}';
      try {
        const parsed = JSON.parse(content) as { title?: string; description?: string };
        return {
          title: parsed.title || "[No title generated]",
          description: parsed.description || "[No description generated]"
        };
      } catch (parseError) {
        console.error('Error parsing JSON response:', (parseError as Error).message);
        return { title: "[Parse Error]", description: "Failed to parse AI response." };
      }
    } catch (error) {
      console.error('Error calling Mistral API:', (error as Error).message);
      return { title: "[Error]", description: "An error occurred during AI processing." };
    }
  }

  async convertAndSummarize(
    pdfPath: string,
    outputDir: string,
  ): Promise<PageSummary[]> {
    const fileHash = await this.getFileHash(pdfPath);
    console.log(`Generated file hash: ${fileHash}`);

    // Reset the class-level processed image hashes (this fixes the memory leak issue)
    this.processedImageHashes.clear();

    // Clear and recreate directory
    console.log(`Clearing output directory: ${outputDir}`);
    await fs.promises.rm(outputDir, { recursive: true, force: true });
    await fs.promises.mkdir(outputDir, { recursive: true });
    console.log(`Output directory recreated: ${outputDir}`);

    console.log('Extracting embedded images...');
    const embeddedImages = await this.extractEmbeddedImages(
      pdfPath,
      outputDir,
      fileHash,
    );
    console.log(`Extracted ${embeddedImages.length} embedded images.`);

    console.log('Starting PDF conversion to PNG images...');
    await Poppler.convert(pdfPath, {
      format: 'png',
      out_dir: outputDir,
      out_prefix: 'page',
    });
    console.log('PDF conversion completed.');

    console.log('Reading and processing pages...');
    const pages = fs
      .readdirSync(outputDir)
      .filter((f) => f.startsWith('page-') && f.endsWith('.png'))
      .sort();

    console.log(`Found ${pages.length} page(s) to process.`);

    const summaries: PageSummary[] = [];

    for (let i = 0; i < pages.length; i++) {
      const file = pages[i];
      const imagePath = join(outputDir, file);

      console.log(`Processing page ${i + 1} of ${pages.length}: ${file}`);

      if (!(await this.isValidImage(imagePath))) {
        console.log(`Skipping invalid image: ${file}`);
        continue;
      }
      if (await this.isDuplicateImage(imagePath)) {
        console.log(`Skipping duplicate image: ${file}`);
        continue;
      }

      console.log(`Recognizing text from image: ${file}`);
      const text = await tesseract.recognize(imagePath, { lang: 'eng' });
      const trimmedText = text.trim();

      if (!trimmedText) {
        console.log(`No text found on page: ${file}`);
        continue;
      }

      console.log(`Text recognition successful, sending text to AI...`);
      const { title, description } = await this.callMistral(trimmedText);

      console.log(
        `AI processed page: ${file}. Title: ${title}, Description: ${description}`,
      );

      console.log('Detecting logos, photos, faces, and scenes...');
      const { logos, photos, faces, scenes } = await this.detectAndCropLogos(
        imagePath,
        outputDir,
        file,
        fileHash,
      );
      console.log(
        `Detected ${logos.length} logo(s), ${photos.length} photo(s), ${faces.length} face(s), and ${scenes.length} scene(s) on page: ${file}`,
      );

      summaries.push({
        imageUrl: `/files/${fileHash}/${file}`,
        title,
        description,
        embeddedImages: i === 0 ? embeddedImages : [],
        logos,
        photos,
        faces,
        scenes,
      });
    }

    console.log('Summarization complete. Returning results...');
    return summaries;
  }

  // This function is intentionally left empty as it's a duplicate of the more robust annotate implementation below
  
  private async detectAndCropLogos(
    imagePath: string,
    outputDir: string,
    pageFilename: string,
    fileHash: string,
  ): Promise<{ logos: string[]; photos: string[]; faces: string[]; scenes: string[] }> {
    console.log(`Starting logo and photo detection for image: ${imagePath}`);

    const imgBuffer = fs.readFileSync(imagePath);
    const logos: string[] = [];
    const photos: string[] = [];
    const faces: string[] = [];
    const scenes: string[] = [];

    try {
      console.log('Starting logo detection...');
      const logoResp: any = await this.annotate(imgBuffer, 'LOGO_DETECTION');
      const { width: imgW = 0, height: imgH = 0 } =
        await sharp(imgBuffer).metadata();
      console.log(`Image dimensions: ${imgW}x${imgH}`);

      for (const [idx, ann] of (logoResp.logoAnnotations || []).entries()) {
        const verts = ann.boundingPoly?.vertices;
        if (!verts || verts.length < 3) continue;

        const xs = verts.map((v: any) => Math.max(0, v.x || 0));
        const ys = verts.map((v: any) => Math.max(0, v.y || 0));

        const minX = Math.min(...xs);
        const minY = Math.min(...ys);
        const wF = Math.max(...xs) - minX;
        const hF = Math.max(...ys) - minY;
        const pad = Math.min(wF, hF) * 0.05;

        const left = Math.max(0, Math.round(minX - pad));
        const top = Math.max(0, Math.round(minY - pad));
        const width = Math.min(imgW - left, Math.round(wF + pad * 2));
        const height = Math.min(imgH - top, Math.round(hF + pad * 2));

        const outputPath = join(
          outputDir,
          `${pageFilename.replace('.png', '')}_logo_${idx}.png`,
        );
        console.log(
          `Extracting logo ${idx} with dimensions: ${width}x${height} at (${left}, ${top})`,
        );
        await sharp(imgBuffer)
          .extract({ left, top, width, height })
          .toFile(outputPath);

        logos.push(
          `/files/${fileHash}/${pageFilename.replace('.png', '')}_logo_${idx}.png`,
        );
      }
      console.log(`Detected ${logos.length} logos.`);
    } catch (error) {
      console.error('Logo detection failed:', (error as Error).message);
    }

    try {
      console.log('Starting object detection...');
      const objResp: any = await this.annotate(
        imgBuffer,
        'OBJECT_LOCALIZATION',
      );
      const { width: W = 0, height: H = 0 } = await sharp(imgBuffer).metadata();
      console.log(`Image dimensions for object detection: ${W}x${H}`);

      // Define photo-related object categories
      const photoCategories = [
        'Person', 'Human', 'Man', 'Woman', 'Child', 'People', 'Group',
        'Photograph', 'Picture frame', 'Image', 'Portrait', 'Photo',
        'Animal', 'Pet', 'Dog', 'Cat', 'Bird', 'Wildlife',
        'Scenery', 'Landscape', 'Building', 'Architecture', 'Landmark'
      ];

      // Track the areas we've already processed to avoid overlapping extractions
      const processedAreas: Array<{ left: number, top: number, width: number, height: number }> = [];

      for (const [idx, ann] of (
        objResp.localizedObjectAnnotations || []
      ).entries()) {
        const verts = ann.boundingPoly?.normalizedVertices;
        if (!verts || verts.length < 3) continue;

        // Check if the object is likely a photo
        const objectName = ann.name || '';
        const score = ann.score || 0;
        const isLikelyPhoto = photoCategories.some(cat =>
          objectName.toLowerCase().includes(cat.toLowerCase())
        ) || score > 0.7;

        // Skip if not likely a photo and not high confidence
        if (!isLikelyPhoto && score < 0.8) continue;

        // Calculate bounding box with normalized coordinates (0-1 range)
        const xs = verts.map((v: any) => Math.max(0, Math.min(1, v.x || 0)));
        const ys = verts.map((v: any) => Math.max(0, Math.min(1, v.y || 0)));
        const minX = Math.min(...xs);
        const minY = Math.min(...ys);
        const maxX = Math.max(...xs);
        const maxY = Math.max(...ys);

        // Convert to pixel coordinates
        const left = Math.max(0, Math.round(minX * W));
        const top = Math.max(0, Math.round(minY * H));
        const width = Math.min(W - left, Math.round((maxX - minX) * W));
        const height = Math.min(H - top, Math.round((maxY - minY) * H));

        // Skip very small objects (likely not photos)
        if (width < 50 || height < 50) {
          console.log(`Skipping small object: ${width}x${height}`);
          continue;
        }

        // Skip if aspect ratio is extreme
        const aspectRatio = width / height;
        if (aspectRatio > 5 || aspectRatio < 0.2) {
          console.log(`Skipping object with extreme aspect ratio: ${aspectRatio}`);
          continue;
        }

        // Check if this area overlaps significantly with an already processed area
        const overlapsExisting = processedAreas.some(area => {
          const xOverlap = Math.max(0, Math.min(area.left + area.width, left + width) - Math.max(area.left, left));
          const yOverlap = Math.max(0, Math.min(area.top + area.height, top + height) - Math.max(area.top, top));
          const overlapArea = xOverlap * yOverlap;
          const thisArea = width * height;
          const existingArea = area.width * area.height;
          // Skip if overlap is more than 70% of either area
          return overlapArea > 0.7 * Math.min(thisArea, existingArea);
        });

        if (overlapsExisting) {
          console.log(`Skipping overlapping object at (${left},${top}) with size ${width}x${height}`);
          continue;
        }

        // Add padding to capture more context
        const padX = Math.round(width * 0.1);
        const padY = Math.round(height * 0.1);
        const paddedLeft = Math.max(0, left - padX);
        const paddedTop = Math.max(0, top - padY);
        const paddedWidth = Math.min(W - paddedLeft, width + padX * 2);
        const paddedHeight = Math.min(H - paddedTop, height + padY * 2);

        // Record this area as processed
        processedAreas.push({ left: paddedLeft, top: paddedTop, width: paddedWidth, height: paddedHeight });

        const outName = `${pageFilename.replace('.png', '')}_obj_${idx}.png`;
        console.log(
          `Extracting object ${idx} (${objectName}) with dimensions: ${paddedWidth}x${paddedHeight} at (${paddedLeft}, ${paddedTop})`,
        );

        try {
          const outputPath = join(outputDir, outName);
          await sharp(imgBuffer)
            .extract({ left: paddedLeft, top: paddedTop, width: paddedWidth, height: paddedHeight })
            .toFile(outputPath);

          // Verify the extracted image exists and is valid
          if (fs.existsSync(outputPath) && await this.isValidImage(outputPath)) {
            photos.push(`/files/${fileHash}/${outName}`);
            console.log(`Successfully extracted and validated photo: ${outName}`);
          } else {
            console.log(`Extracted image failed validation: ${outName}`);
            if (fs.existsSync(outputPath)) {
              fs.unlinkSync(outputPath);
            }
          }
        } catch (extractError) {
          console.error(`Error extracting object: ${(extractError as Error).message}`);
        }
      }
      console.log(`Detected ${photos.length} photos from objects.`);
    } catch (error) {
      console.error('Object detection failed:', (error as Error).message);
    }

    // Face detection to find photos with people
    try {
      console.log('Starting face detection...');
      const faceResp: any = await this.annotate(imgBuffer, 'FACE_DETECTION');
      const { width: faceW = 0, height: faceH = 0 } = await sharp(imgBuffer).metadata();
      console.log(`Image dimensions for face detection: ${faceW}x${faceH}`);

      // Track areas we've already processed to avoid duplicates
      const processedFaceAreas: Array<{ left: number, top: number, width: number, height: number }> = [];

      for (const [idx, ann] of (faceResp.faceAnnotations || []).entries()) {
        // Skip low confidence faces
        const detectionConfidence = ann.detectionConfidence || 0;
        if (detectionConfidence < 0.7) {
          console.log(`Skipping low confidence face: ${detectionConfidence}`);
          continue;
        }

        const boundingPoly = ann.boundingPoly?.vertices;
        if (!boundingPoly || boundingPoly.length < 4) {
          console.log('Skipping face with invalid bounding polygon');
          continue;
        }

        // Get face coordinates
        const xs = boundingPoly.map((v: any) => Math.max(0, v.x || 0));
        const ys = boundingPoly.map((v: any) => Math.max(0, v.y || 0));
        const minX = Math.min(...xs);
        const minY = Math.min(...ys);
        const maxX = Math.max(...xs);
        const maxY = Math.max(...ys);
        const width = maxX - minX;
        const height = maxY - minY;

        // Skip tiny faces
        if (width < 20 || height < 20) {
          console.log(`Skipping tiny face: ${width}x${height}`);
          continue;
        }

        // Add generous padding to include more of the person
        // Use a portrait-style crop (more below the face than above)
        const padX = Math.round(width * 1.2); // Horizontal padding
        const padYTop = Math.round(height * 0.8); // Less padding above face
        const padYBottom = Math.round(height * 2); // More padding below face

        const left = Math.max(0, minX - padX);
        const top = Math.max(0, minY - padYTop);
        const paddedWidth = Math.min(faceW - left, width + padX * 2);
        const paddedHeight = Math.min(faceH - top, height + padYTop + padYBottom);

        // Check for overlap with existing face crops
        const overlapsExisting = processedFaceAreas.some(area => {
          const xOverlap = Math.max(0, Math.min(area.left + area.width, left + paddedWidth) - Math.max(area.left, left));
          const yOverlap = Math.max(0, Math.min(area.top + area.height, top + paddedHeight) - Math.max(area.top, top));
          const overlapArea = xOverlap * yOverlap;
          const thisArea = paddedWidth * paddedHeight;
          const existingArea = area.width * area.height;
          // Skip if overlap is more than 50% of either area
          return overlapArea > 0.5 * Math.min(thisArea, existingArea);
        });

        if (overlapsExisting) {
          console.log(`Skipping overlapping face at (${left},${top}) with size ${paddedWidth}x${paddedHeight}`);
          continue;
        }

        // Record this area as processed
        processedFaceAreas.push({ left, top, width: paddedWidth, height: paddedHeight });

        const outName = `${pageFilename.replace('.png', '')}_face_${idx}.png`;
        console.log(
          `Extracting face ${idx} with dimensions: ${paddedWidth}x${paddedHeight} at (${left}, ${top})`,
        );

        try {
          const outputPath = join(outputDir, outName);
          await sharp(imgBuffer)
            .extract({ left, top, width: paddedWidth, height: paddedHeight })
            .toFile(outputPath);

          // Verify the extracted image exists and is valid
          if (fs.existsSync(outputPath) && await this.isValidImage(outputPath)) {
            faces.push(`/files/${fileHash}/${outName}`);
            console.log(`Successfully extracted and validated face: ${outName}`);
          } else {
            console.log(`Extracted face image failed validation: ${outName}`);
            if (fs.existsSync(outputPath)) {
              fs.unlinkSync(outputPath);
            }
          }
        } catch (extractError) {
          console.error(`Error extracting face: ${(extractError as Error).message}`);
        }
      }
      console.log(`Detected ${faces.length} faces.`);
    } catch (error) {
      console.error('Face detection failed:', (error as Error).message);
    }

    // Scene detection to find landscape photos
    try {
      console.log('Starting scene detection...');
      const labelResp: any = await this.annotate(imgBuffer, 'LABEL_DETECTION');
      const { width: imgWidth = 0, height: imgHeight = 0 } = await sharp(imgBuffer).metadata();

      // Define scene-related categories with higher specificity
      const sceneCategories = {
        nature: ['landscape', 'scenery', 'nature', 'outdoor', 'beach', 'mountain', 'forest', 'lake', 'ocean', 'river', 'sky', 'sunset', 'sunrise', 'clouds', 'field', 'garden', 'park', 'trees', 'waterfall', 'valley', 'hill', 'desert'],
        urban: ['building', 'architecture', 'landmark', 'cityscape', 'urban', 'city', 'skyline', 'street', 'downtown', 'monument', 'tower', 'bridge', 'skyscraper'],
        interior: ['room', 'interior', 'indoor', 'furniture', 'office', 'home', 'house', 'apartment', 'hotel', 'restaurant', 'museum', 'gallery']
      };

      // Only process if we have high confidence scene labels
      const sceneLabels = (labelResp.labelAnnotations || [])
        .filter((label: any) => {
          const score = label.score || 0;
          const description = (label.description || '').toLowerCase();

          // Check if the label matches any scene category
          const isNatureScene = sceneCategories.nature.some(term => description.includes(term));
          const isUrbanScene = sceneCategories.urban.some(term => description.includes(term));
          const isInteriorScene = sceneCategories.interior.some(term => description.includes(term));

          const isSceneLabel = isNatureScene || isUrbanScene || isInteriorScene;
          return isSceneLabel && score > 0.75; // Higher confidence threshold
        });

      console.log(`Found ${sceneLabels.length} scene labels: ${sceneLabels.map((l: any) => l.description).join(', ')}`);

      if (sceneLabels.length > 0) {
        // Instead of copying the whole page, try to identify the scenic portion
        // First check if we already have a crop from object detection that might be a scene
        const existingSceneCrop = photos.some(photoPath => {
          // Check if any of the detected objects is large enough to be a scene
          const filename = path.basename(photoPath);
          return filename.includes('_obj_') &&
            filename.startsWith(pageFilename.replace('.png', ''));
        });

        if (!existingSceneCrop) {
          // If no existing scene crop, create one by analyzing the image
          // For simplicity, we'll use a smart cropping approach
          const outName = `${pageFilename.replace('.png', '')}_scene.png`;
          const outputPath = join(outputDir, outName);

          try {
            // Use sharp's attention strategy to focus on the interesting part of the image
            // This is better than just copying the whole page
            const cropData = await sharp(imgBuffer)
              .metadata()
              .then(metadata => {
                // Calculate a reasonable crop size (not the full page)
                const cropWidth = Math.min(metadata.width || 0, 1200); // Limit max width
                const cropHeight = Math.min(metadata.height || 0, 1200); // Limit max height

                // Use a 3:2 or 16:9 aspect ratio if possible
                const targetRatio = 3 / 2; // Landscape photo ratio
                const currentRatio = cropWidth / cropHeight;

                let finalWidth = cropWidth;
                let finalHeight = cropHeight;

                if (currentRatio > targetRatio) {
                  // Image is wider than target ratio
                  finalWidth = Math.round(finalHeight * targetRatio);
                } else {
                  // Image is taller than target ratio
                  finalHeight = Math.round(finalWidth / targetRatio);
                }

                return { width: finalWidth, height: finalHeight };
              });

            // Use attention strategy to focus on the interesting part
            await sharp(imgBuffer)
              .resize({
                width: cropData.width,
                height: cropData.height,
                fit: 'cover',
                position: 'attention' // This uses image content to determine the crop position
              })
              .toFile(outputPath);

            // Verify the extracted image is valid
            if (fs.existsSync(outputPath) && await this.isValidImage(outputPath)) {
              scenes.push(`/files/${fileHash}/${outName}`);
              console.log(`Successfully extracted scene: ${outName}`);
              console.log(`Scene labels: ${sceneLabels.map((l: any) => `${l.description} (${l.score})`).join(', ')}`);
            } else {
              console.log(`Extracted scene failed validation`);
              if (fs.existsSync(outputPath)) {
                fs.unlinkSync(outputPath);
              }
            }
          } catch (error) {
            console.error(`Error extracting scene: ${(error as Error).message}`);
          }
        } else {
          console.log(`Using existing object detection as scene image`);
        }
      }

      console.log(`Detected ${scenes.length} scenes.`);
    } catch (error) {
      console.error('Scene detection failed:', (error as Error).message);
    }

    console.log(
      `Detection complete. Found ${logos.length} logos, ${photos.length} objects, ${faces.length} faces, and ${scenes.length} scenes.`,
    );
    return { logos, photos, faces, scenes };
      } else {
        console.log(`Extracted scene failed validation`);
        if (fs.existsSync(outputPath)) {
          fs.unlinkSync(outputPath);
        }
      }

      return response;
    } catch (error) {
      console.error('Annotation failed:', (error as Error).message);
      throw error; // Re-throwing the error for further handling if necessary
    }
  }

  private async callMistral(
    text: string,
    retries = 3,
    backoff = 1000,
  ): Promise<{ title: string; description: string }> {
    if (!this.mistralKey) {
      console.error('MISTRAL_API_KEY is missing.');
      throw new HttpException(
        'Missing MISTRAL_API_KEY',
        HttpStatus.INTERNAL_SERVER_ERROR,
      );
    }

    const systemPrompt = `
  You are a data summarization assistant.
  1. Extract the single most descriptive **title** (no more than 10 words).
  2. Extract all the key facts, figures, dates, and entities, and then produce
     a concise **description** (two sentences max) that integrates those facts.
  3. Return ONLY valid JSON with fields "title" and "description", e.g.:
  
  {
    "title": "Autonomous Forklift Market Growth",
    "description": "Global autonomous forklift revenue is projected at $59.79 B in 2025 at a 3.46% CAGR through 2030, with North America leading and Asia Pacific fastest-growing; further AI-driven use cases will emerge through 2037."
  }
  `.trim();

    const userPrompt = `
  Text:
  ${text}
  `.trim();

    for (let attempt = 1; attempt <= retries; attempt++) {
      try {
        const res = await fetch(this.mistralUrl, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            Authorization: `Bearer ${this.mistralKey}`,
          },
          body: JSON.stringify({
            model: 'open-mistral-7b',
            messages: [
              { role: 'system', content: systemPrompt },
              { role: 'user', content: userPrompt },
            ],
          }),
        });

        if (!res.ok) {
          if (res.status === 429 && attempt < retries) {
            console.warn(
              `Rate-limited (429); retrying in ${backoff * attempt}ms…`,
            );
            await new Promise((r) => setTimeout(r, backoff * attempt));
            continue;
          }
          throw new HttpException(
            `Mistral API error: ${res.status} ${res.statusText}`,
            HttpStatus.BAD_GATEWAY,
          );
        }

        const payload = (await res.json()) as {
          choices: { message: { content: string } }[];
        };
        const content = payload.choices?.[0]?.message.content?.trim() || '';

        // Attempt to parse clean JSON out of the content
        let data: { title: string; description: string };
        try {
          // In case the model wraps JSON in backticks or markdown fences
          const jsonText = content
            .replace(/```json\s*([\s\S]*?)```/, '$1')
            .replace(/```([\s\S]*?)```/, '$1')
            .trim();
          data = JSON.parse(jsonText);
        } catch (parseErr) {
          console.error('Failed to parse JSON from Mistral:', content);
          throw new HttpException(
            'Invalid JSON from Mistral',
            HttpStatus.BAD_GATEWAY,
          );
        }

        return {
          title: data.title.trim(),
          description: data.description.trim(),
        };
      } catch (err) {
        console.error(
          `Mistral attempt ${attempt} error:`,
          (err as Error).message,
        );
        if (attempt === retries) {
          throw new HttpException(
            'Failed to get title/description from Mistral after retries',
            HttpStatus.BAD_GATEWAY,
          );
        }
        await new Promise((r) => setTimeout(r, backoff * attempt));
      }
    }

    // Unreachable
    return { title: '', description: '' };
  }
}
